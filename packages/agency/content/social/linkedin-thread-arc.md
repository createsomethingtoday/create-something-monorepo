# LinkedIn Thread: Arc Case Study

**Campaign:** GTM Sprint 2 - Social Thread
**Target:** LinkedIn
**Type:** 7-tweet thread
**CTA:** createsomething.agency/discover

---

## Thread

### Tweet 1 (Hook)

Most AI implementations fail because they try to replace humans entirely.

We helped Arc reduce manual review time by 73%—by identifying what actually needed human judgment.

Here's what happened when we stopped automating everything:

---

### Tweet 2 (Problem)

Arc was drowning in manual reviews.

Every new customer meant:
- 8-12 documents to process
- 40+ risk criteria to check
- 4.2 hours of manual work
- Growing backlog, declining quality

They'd tried RPA tools, offshore teams, generic AI.

Nothing stuck.

---

### Tweet 3 (Insight)

The breakthrough came from a two-week discovery sprint.

We found the 80/20 pattern hiding in plain sight:

**80%** of applications followed predictable patterns.
**20%** required genuine human judgment.

The previous solutions failed because they treated all cases the same.

---

### Tweet 4 (Approach)

We built a three-layer system:

**Layer 1:** Document Intelligence
Extract data from 47 document variations automatically.

**Layer 2:** Risk Assessment Engine
Rules for compliance, ML for patterns, confidence scores for everything.

**Layer 3:** Human-in-the-Loop
Dashboard for edge cases. Feedback that improves the model.

---

### Tweet 5 (Results)

8 weeks later:

**4.2 hours → 1.1 hours** average processing time
**73%** reduction in manual work
**94%** accuracy on automated assessments
**$180K** annual operational savings

But the real metric: the team stopped firefighting and started thinking.

---

### Tweet 6 (Principle)

The goal isn't to remove humans from the loop.

It's to put them where they belong—handling the cases that actually need judgment.

Good AI knows what it doesn't know.
Great AI escalates gracefully.

---

### Tweet 7 (CTA)

If your operations team is scaling slower than your customer growth:

createsomething.agency/discover

We'll map your workflow and identify what actually needs automation.

Sometimes the answer is less AI, better placed.

---

## Formatting Notes

**LinkedIn-specific formatting:**

1. **Line breaks** - Use blank lines between thoughts for mobile readability
2. **Numbers bold** - Key metrics should stand out
3. **Percentage format** - Use % symbol, not "percent"
4. **No emoji** - Per voice guidelines
5. **Hashtags** - Add sparingly at end of final tweet only

**Suggested hashtags (optional, add to Tweet 7):**
- #AIImplementation
- #OperationsAutomation
- #B2BSaaS

---

## Voice Compliance Checklist

- [x] All claims backed by specific metrics (73%, 4.2 to 1.1 hours, $180K)
- [x] Time/cost comparisons included (8 weeks, annual savings)
- [x] Methodology transparent (three-layer system explained)
- [x] Limitations acknowledged ("80/20 pattern" implies not everything automated)
- [x] Solves a real problem (operational scaling)
- [x] Principle articulated (humans where judgment needed)
- [x] No marketing jargon
- [x] Direct, declarative sentences
- [x] Specific over vague

---

## Differentiation from Kickstand Thread

| Aspect | Kickstand | Arc |
|--------|-----------|-----|
| Problem type | Technical debt | Operational scaling |
| Solution | Subtraction (155→13) | Augmentation (human+AI) |
| Philosophy | "Less, but better" | "Humans where judgment needed" |
| Metrics focus | Reduction | Efficiency |
| Framework | Subtractive Triad | 80/20 + Human-in-Loop |

These threads complement each other: Kickstand shows we can simplify, Arc shows we can augment.

---

## Source References

- Full case study: createsomething.agency/work/arc
- Detailed write-up: packages/agency/content/case-studies/arc.md

---

## Posting Instructions

1. Post as individual LinkedIn updates or use native thread feature
2. Space posts 2-3 hours apart if posting separately (longer gap than Kickstand for variety)
3. Best times: Tuesday-Thursday, 8-10am or 5-6pm
4. Engage with comments in first 30 minutes for algorithm boost
5. Post at least 1 week after Kickstand thread for content spacing

---

## Condensed Version (for X/Twitter)

For X/Twitter character limits, use this condensed 5-post version:

**1.** Most AI implementations fail because they try to replace humans entirely. We helped Arc reduce manual review time by 73%—by identifying what actually needed human judgment.

**2.** Arc was drowning: 4.2 hours per review, 40+ criteria to check, growing backlog. They'd tried RPA, offshore, generic AI. Nothing stuck. The 80/20 pattern was hiding in plain sight.

**3.** 80% of cases followed predictable patterns. 20% required genuine judgment. Previous solutions failed because they treated all cases the same. We built for both.

**4.** Results: 4.2 hours → 1.1 hours (73% reduction). 94% accuracy on automated assessments. $180K annual savings. The team stopped firefighting.

**5.** The goal isn't removing humans. It's putting them where judgment matters. If operations scales slower than customers: createsomething.agency/discover

---

## A/B Testing Notes

Consider testing these hook variations:

**Hook A (Current):**
"Most AI implementations fail because they try to replace humans entirely."

**Hook B (Contrarian):**
"We told Arc to use less AI, not more. They saved $180K."

**Hook C (Question):**
"Why do 73% of AI implementations fail to deliver ROI?"

Track engagement rates to inform future thread hooks.
